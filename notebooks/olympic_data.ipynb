{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLab Python for Data Analysis Walkthrough. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few notes before we get started.\n",
    "\n",
    "This project is on github. To download enter the following on the commandline.\n",
    "```\n",
    "git clone https://github.com/asfox/DataLab_PythonWorkshop_Olympics.git\n",
    "\n",
    "```\n",
    "\n",
    "I used [cookiecutter](https://cookiecutter.readthedocs.io/en/1.7.0/index.html) to organize this project. I'd recommend you do the same with your own projects. For something like this, it's probably overkill, but it's a good habit to start. To install cookiecutter, run the following on the commandline. \n",
    "\n",
    "``` \n",
    "pip install cookiecutter\n",
    "\n",
    "cookiecutter https://github.com/drivendata/cookiecutter-data-science\n",
    "# then follow the prompts.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Jupyter Notebook\n",
    "### this is _Markdown_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing to do is import some packages. \n",
    "\n",
    "Packages are just objects that you get from other files. Objects can have functions and hold data. Often when the object gets super complicated, people package it together into a nice, clean oject with some accompanying documentation. \n",
    "\n",
    "Not having all possible packages loaded by default allows python to load and run faster, only taking the time for things you need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pandas** will allow you to use DataFrames in python. \n",
    "\n",
    "**matplotlib** is the workhorse of plotting in python. \n",
    "\n",
    "**seaborn** is effectively a wrapper for matplotlib that makes science plotting easier. \n",
    "\n",
    "**numpy** will do most mathamatical operations (and matrix operations) in python (QUICKLY!)\n",
    "\n",
    "**re** will allow you to use regular expressions in python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load our first dataset. \n",
    "\n",
    "This is data on olympians from a csv I found online. It's in the github. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_olympics = pd.read_csv('../data/raw/athlete_events.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Pro tip:_ make sure you get the path right!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_olympics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset and organize your dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_olympics = df_olympics[df_olympics['Season']=='Summer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winners = df_olympics.groupby(['Team', 'Medal', 'Year']).count()['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winners.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winners.unstack('Medal')\n",
    "df_winners = df_winners.unstack('Medal').fillna(0).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Pro tip:_ pandas can stack, unstack, melt, and piviot. If those mean something to you, great. If not, these are good things to google, when you are stuck trying to re-form a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winners.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winners['Total Medals'] = df_winners[['Bronze', 'Gold', 'Silver']].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Pro tip:_ It's good practice to keep all your data manipulations in the same place. This way, you don't run into trouble overwriting/changing data when you run cells in the wrong order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1,figsize=(16,4))\n",
    "ax = sns.barplot(x='Team', y='Gold', data=df_winners.loc[df_winners['Year']==1992])\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=90);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1,figsize=(16,4))\n",
    "ax = sns.swarmplot(x='Team', y='Gold', data=df_winners.loc[df_winners['Year']>=1981])\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=90);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot('Gold', 'Bronze', data=df_winners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1,figsize=(16,4))\n",
    "ax = sns.barplot(x='Team', y='Total Medals', data=df_winners.loc[df_winners['Year']==1992])\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=90);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge:\n",
    "\n",
    "Do the same countries win the winter olympics? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Are winners just big countries? \n",
    "\n",
    "Load, clean, and merge our next dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load population data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop = pd.read_csv('../data/raw/population-figures-by-country-csv.csv')\n",
    "df_pop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean population data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, it's annoying to have variables named \"Year_1961\". Let's just fix that with a regular expression. \n",
    "\n",
    "Here I'm passing a function to the rename function -- I know. Fancy!\n",
    "\n",
    "This is the kind of thing you can usually just find on stackoverflow (like I did!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop = df_pop.rename(columns=lambda x: re.sub('^Year_','',x))\n",
    "df_pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop = df_pop.melt(id_vars=['Country', 'Country_Code'])\n",
    "df_pop.columns = ['Country', 'Country_Code', 'Year', 'Population']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Pro tip:_ **One of the most common problems people run into involve trying to do this without thinking about it.**\n",
    "\n",
    "Here's another place where I used a DataFrame function to reshape my data. It really helps to have in mind what you want your new DataFrame to look like. I usually start out with a drawing on paper or a picture in my mind. Once you have that, you can run the command you want (or google for it)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_winners.head()\n",
    "df_pop.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge olympic data with population data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop_winner = df_winners.merge(df_pop, left_on=['Team','Year'], \n",
    "                                 right_on=['Country', 'Year'], how='inner' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error messeges!\n",
    "\n",
    "Make sure to read your error messeges from bottom to top. \n",
    "\n",
    "The last line will tell you the error. The lines above it will give you some context about the code that ran the errant code. The lines above that will give you some context about the lines that ran the code that ran the errant code. And so on. \n",
    "\n",
    "This particular error is a version of the notorious _TypeError_ that I mentioned... In this case it get's called a _ValueError_ but the problem is that I'm trying to merge files of different types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_pop['Year'].dtype, print(df_winners['Year'].dtype ) )\n",
    "# df_pop['Year'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the error by doing a better job at cleaning data\n",
    "\n",
    "If this weren't a tutorial, I'd add this code above, before I tried to merge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop['Year'] = pd.to_numeric(df_pop['Year'])\n",
    "print(df_pop['Year'].dtype, print(df_winners['Year'].dtype ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now merge data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop_winner = df_winners.merge(df_pop, left_on=['Team','Year'], \n",
    "                                 right_on=['Country', 'Year'], how='inner' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop_winner.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot merged data\n",
    "\n",
    "Now we can plot medals against population across contries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot('Bronze', 'Population', data=df_pop_winner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe the distribution is messing us up? Let's log-scale and try again... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop_winner['log10(Population)'] = np.log10(df_pop_winner['Population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot('Bronze', 'log10(Population)', data=df_pop_winner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge:\n",
    "Can you re-organize your version of the notebook so that we avoid erorrs and edit our data all in one place? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Are rich countries winning?\n",
    "\n",
    "I downloaded GDP data from online. This data is also in the github. \n",
    "\n",
    "https://data.worldbank.org/indicator/NY.GDP.MKTP.CD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdp_raw = pd.read_csv('../data/raw/API_NY/API_NY.GDP.MKTP.CD_DS2_en_csv_v2_820841.csv', \n",
    "                  skiprows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdp_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the GDP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_gdp_raw.columns)\n",
    "df_gdp_raw.drop( columns='Unnamed: 64', inplace=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is closer to how a good notebook _**should**_ look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdp = df_gdp_raw.melt(id_vars=['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code'])\n",
    "\n",
    "# select only GDP in current USD\n",
    "df_gdp = df_gdp[ df_gdp['Indicator Name'] == 'GDP (current US$)' ]\n",
    "\n",
    "# select columns, and fix names\n",
    "df_gdp = df_gdp[['Country Name', 'Country Code', 'Indicator Name', 'variable', 'value']]\n",
    "df_gdp.columns = ['Country Name', 'Country Code', 'Indicator Name', 'Year', 'GDP']\n",
    "\n",
    "# convert year to numeric\n",
    "df_gdp['Year'] = pd.to_numeric( df_gdp['Year'] )\n",
    "\n",
    "# convert GDP to numeric\n",
    "df_gdp['GDP (in USD)'] = pd.to_numeric( df_gdp['GDP'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge olympic medal data and GDP data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdp_winner = df_winners.merge(df_gdp, left_on=['Team','Year'], \n",
    "                                 right_on=['Country Name', 'Year'], how='inner' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdp_winner.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot olympic medals and GDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot('Bronze', 'GDP', data=df_gdp_winner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create new variables\n",
    "\n",
    "_If_ we were doing this not as a tutorial, this should be moved up, before we merge and plot. For a workshop or tutorial, I think it's clearer here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gdp_winner['log10(GDP)'] = np.log10(df_gdp_winner['GDP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot log-scaled medals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot('Total Medals', 'log10(GDP)', data=df_gdp_winner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create three subplots using matplotlib\n",
    "f, ax_list = plt.subplots(1,3, figsize=(15,5))\n",
    "\n",
    "# plot each medal on a different subplot\n",
    "sns.scatterplot('Bronze', 'log10(GDP)', data=df_gdp_winner, ax=ax_list[0], color=sns.xkcd_rgb['bronze'])\n",
    "sns.scatterplot('Silver', 'log10(GDP)', data=df_gdp_winner, ax=ax_list[1], color=sns.xkcd_rgb['silver'])\n",
    "sns.scatterplot('Gold', 'log10(GDP)', data=df_gdp_winner, ax=ax_list[2], color=sns.xkcd_rgb['gold'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "# if we pass the same axis, to each plot, we can make them overlap. \n",
    "bronze = sns.scatterplot('Bronze', 'log10(GDP)', data=df_gdp_winner, ax=ax, alpha=.3, color=sns.xkcd_rgb['brown'])\n",
    "silver = sns.scatterplot('Silver', 'log10(GDP)', data=df_gdp_winner, ax=ax, alpha=.3, color=sns.xkcd_rgb['silver'])\n",
    "gold = sns.scatterplot('Gold', 'log10(GDP)', data=df_gdp_winner, ax=ax, alpha=.3, color=sns.xkcd_rgb['gold'])\n",
    "\n",
    "# set our axis x-label\n",
    "ax.set_xlabel('Medals')\n",
    "\n",
    "# Add a legend. Because we did this across different plots, \n",
    "# we need to create a custom legend. Custom legends can be annoying. \n",
    "from matplotlib.lines import Line2D\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label='Bronze',\n",
    "                          markerfacecolor=sns.xkcd_rgb['brown'], markersize=10),\n",
    "                   Line2D([0], [0], marker='o', color='w', label='Silver',\n",
    "                          markerfacecolor=sns.xkcd_rgb['silver'], markersize=10),\n",
    "                  Line2D([0], [0], marker='o', color='w', label='Gold',\n",
    "                          markerfacecolor=sns.xkcd_rgb['gold'], markersize=10),]\n",
    "\n",
    "# In an ideal world, we would only need this line. \n",
    "#   That would have been the case if we were clever and \n",
    "#   found a way to make this using one plot command.\n",
    "ax.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "# save the figure into our reports/figures!\n",
    "plt.savefig( '../reports/figures/Log10GDP_vs_OlympicMedals.png', bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save our processsed data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all the data that we've worked with into one dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop_gdp_winner = df_pop_winner.merge(df_gdp, left_on=['Team','Year'], \n",
    "                                 right_on=['Country Name', 'Year'], how='inner' )\n",
    "df_pop_gdp_winner.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the merged dataframe as as .csv file in the processed data foler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop_gdp_winner.to_csv('../data/processed/merged_winner_pop_gdp.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Pro tip:_ if you don't need your index, don't save it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
